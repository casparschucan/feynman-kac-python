{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "108d37ce-58e9-430b-8c05-0df3060a575a",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be813589-3831-4e2d-be7e-9aedd51890ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mlmc import mlmc  # Assuming this is how you import the function\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def benchmark_mlmc(parameter_sets, runs=5):\n",
    "    \"\"\"\n",
    "    Benchmark the mlmc function with different parameter sets.\n",
    "\n",
    "    Args:\n",
    "        parameter_sets: List of dictionaries, each containing parameters for mlmc\n",
    "        runs: Number of times to run each parameter set for averaging\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with benchmark results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for params in parameter_sets:\n",
    "        total_time = 0\n",
    "        total_cost = 0\n",
    "        avg_error = 0\n",
    "        max_levels = []\n",
    "\n",
    "        solution = params[\"f\"]\n",
    "        x = params[\"x\"]\n",
    "        y = params[\"y\"]\n",
    "        \n",
    "        for _ in tqdm(range(runs)):\n",
    "            start_time = time.time()\n",
    "            expectation, cost, max_level, _ = mlmc(**params)\n",
    "            end_time = time.time()\n",
    "\n",
    "            total_time += (end_time - start_time)\n",
    "            total_cost += cost\n",
    "            max_levels.append(max_level)\n",
    "            error = abs(expectation - solution(x, y))\n",
    "            avg_error += error\n",
    "\n",
    "        avg_error /= runs\n",
    "        results.append({\n",
    "            **params,\n",
    "            'avg_execution_time': total_time / runs,\n",
    "            'avg_computational_cost': total_cost / runs,\n",
    "            'avg_max_level': sum(max_levels) / len(max_levels),\n",
    "            'expectation': expectation,  # Last computed value\n",
    "            'avg_error': avg_error\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aaa1c1-4cfa-4e51-9eb7-5526bf045bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7990a287977e46d0876f59c7ad9861ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e29d71b78db412eae54f0adbd60dc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cb17caa0bf47d28c21e96130ec589e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5e5e71c494424f9b8836c7e8486cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example test functions from your notebook\n",
    "from test_functions import sin, sin_rhs, cos, cos_rhs, sq_cos, sq_cos_rhs\n",
    "from test_functions import gaussian, gaussian_rhs, exp, exp_rhs\n",
    "from test_functions import poly, poly_rhs\n",
    "# Define parameter sets to benchmark\n",
    "parameter_sets = [\n",
    "    # Varying epsilon (accuracy)\n",
    "    {'x': 0.5, 'y': 0.5, 'f': sin, 'g': sin_rhs, 'dt0': 0.01, 'epsilon': 0.1},\n",
    "    {'x': 0.5, 'y': 0.5, 'f': sin, 'g': sin_rhs, 'dt0': 0.01, 'epsilon': 0.025},\n",
    "    {'x': 0.5, 'y': 0.5, 'f': sin, 'g': sin_rhs, 'dt0': 0.01, 'epsilon': 0.1/(4**2)},\n",
    "\n",
    "    # Varying dt0 (initial time step)\n",
    "    {'x': 0.5, 'y': 0.5, 'f': sin, 'g': sin_rhs, 'dt0': 0.1, 'epsilon': 0.01},\n",
    "    {'x': 0.5, 'y': 0.5, 'f': sin, 'g': sin_rhs, 'dt0': 0.01, 'epsilon': 0.01},\n",
    "    {'x': 0.5, 'y': 0.5, 'f': sin, 'g': sin_rhs, 'dt0': 0.001, 'epsilon': 0.01},\n",
    "    {'x': 0.5, 'y': 0.5, 'f': sin, 'g': sin_rhs, 'dt0': 0.0001, 'epsilon': 0.01},\n",
    "\n",
    "    # Different test functions\n",
    "    {'x': 0.5, 'y': 0.5, 'f': cos, 'g': cos_rhs, 'dt0': 0.01, 'epsilon': 0.01},\n",
    "    {'x': 0.5, 'y': 0.5, 'f': sq_cos, 'g': sq_cos_rhs, 'dt0': 0.01, 'epsilon': 0.01},\n",
    "    {'x': 0.5, 'y': 0.5, 'f': gaussian, 'g': gaussian_rhs, 'dt0': 0.01, 'epsilon': 0.01},\n",
    "    {'x': 0.5, 'y': 0.5, 'f': exp, 'g': exp_rhs, 'dt0': 0.01, 'epsilon': 0.01},\n",
    "    {'x': 0.5, 'y': 0.5, 'f': poly, 'g': poly_rhs, 'dt0': 0.01, 'epsilon': 0.01},\n",
    "\n",
    "\n",
    "    # Different coordinates\n",
    "    {'x': 0.25, 'y': 0.75, 'f': sin, 'g': sin_rhs, 'dt0': 0.01, 'epsilon': 0.01},\n",
    "]\n",
    "\n",
    "# Run benchmarks\n",
    "benchmark_results = benchmark_mlmc(parameter_sets, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6bac52-2531-4ce9-b2dc-d242c1ee14ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display results table\n",
    "print(benchmark_results)\n",
    "\n",
    "# Plot execution time vs epsilon\n",
    "plt.figure(figsize=(10, 6))\n",
    "epsilon_results = benchmark_results[benchmark_results['x'] == 0.5]\n",
    "epsilon_results = epsilon_results[epsilon_results['dt0'] == 0.01]\n",
    "epsilon_results = epsilon_results[epsilon_results['f'] == sin]\n",
    "epsilon_results = epsilon_results.sort_values('epsilon')\n",
    "\n",
    "plt.loglog(epsilon_results['epsilon'], epsilon_results['avg_execution_time'], 'o-', label='Execution Time')\n",
    "plt.loglog(epsilon_results['epsilon'], epsilon_results['avg_computational_cost'], 's-', label='Computational Cost')\n",
    "plt.xlabel('Epsilon (tolerance)')\n",
    "plt.ylabel('Time/Cost (log scale)')\n",
    "plt.title('MLMC Performance vs Tolerance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot max level vs epsilon\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(epsilon_results['epsilon'], epsilon_results['avg_max_level'], 'o-')\n",
    "plt.xlabel('Epsilon (tolerance)')\n",
    "plt.ylabel('Average Max Level')\n",
    "plt.title('MLMC Max Level vs Tolerance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f0175f-bd9d-4220-895a-cee3281da84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function_results = benchmark_results\n",
    "function_results = benchmark_results[benchmark_results['x'] == 0.5]\n",
    "function_results = function_results[function_results['dt0'] == 0.01]\n",
    "function_results = function_results[function_results['epsilon'] == 0.01]\n",
    "\n",
    "test_functions = {\"Sine\": sin,\n",
    "                  \"Cosine\": cos,\n",
    "                  \"Cosine^2\": sq_cos,\n",
    "                  \"Polynomial\": poly,\n",
    "                  \"Gaussian\": gaussian,\n",
    "                  \"Exponential\": exp}\n",
    "\n",
    "times = [function_results[function_results['f'] == func]['avg_execution_time'].values[0] for func in test_functions.values()]\n",
    "print(times)\n",
    "\n",
    "# Create boxplot of execution times\n",
    "plt.figure(figsize=(12, 8))\n",
    "boxplot = plt.bar(\n",
    "    list(test_functions.keys()),\n",
    "    times\n",
    ")\n",
    "\n",
    "plt.title('Execution Time Comparison for Different Test Functions with epsilon=.01')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898630e-56cd-41d2-aab4-a57554999d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_result = benchmark_results\n",
    "dt_result = benchmark_results[benchmark_results['x'] == 0.5]\n",
    "dt_result = dt_result[dt_result['f'] == sin]\n",
    "dt_result = dt_result[dt_result['epsilon'] == 0.01]\n",
    "\n",
    "test_functions = {\"Sine\": sin,\n",
    "                  \"Cosine\": cos,\n",
    "                  \"Cosine^2\": sq_cos,\n",
    "                  \"Polynomial\": poly,\n",
    "                  \"Gaussian\": gaussian,\n",
    "                  \"Exponential\": exp}\n",
    "\n",
    "times = dt_result['avg_execution_time'].values\n",
    "print(times)\n",
    "dts = dt_result['dt0'].values\n",
    "print(dts)\n",
    "\n",
    "# Create boxplot of execution times\n",
    "plt.figure(figsize=(12, 8))\n",
    "boxplot = plt.semilogx(\n",
    "    dts,\n",
    "    times\n",
    ")\n",
    "plt.scatter(dts, times)\n",
    "plt.title('Execution Time Comparison for Different starting dt')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771d426-3ee0-447d-923a-5133e2becd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function_results = benchmark_results\n",
    "function_results = benchmark_results[benchmark_results['x'] == 0.5]\n",
    "function_results = function_results[function_results['dt0'] == 0.01]\n",
    "function_results = function_results[function_results['epsilon'] == 0.01]\n",
    "\n",
    "test_functions = {\"Sine\": sin,\n",
    "                  \"Cosine\": cos,\n",
    "                  \"Cosine^2\": sq_cos,\n",
    "                  \"Polynomial\": poly,\n",
    "                  \"Gaussian\": gaussian,\n",
    "                  \"Exponential\": exp}\n",
    "\n",
    "times = [function_results[function_results['f'] == func]['avg_error'].values[0] for func in test_functions.values()]\n",
    "print(times)\n",
    "\n",
    "# Create boxplot of execution times\n",
    "plt.figure(figsize=(12, 8))\n",
    "boxplot = plt.bar(\n",
    "    list(test_functions.keys()),\n",
    "    times\n",
    ")\n",
    "\n",
    "plt.title('Error Comparison for Different Test Functions with epsilon=.01')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7048c89-0ae6-4967-8429-1747dd2654bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
